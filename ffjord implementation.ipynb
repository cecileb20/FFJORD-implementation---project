{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**FFJORD implementation**\n",
        "INTRO TO AI class,\n",
        "2025/10/26\n",
        "\n",
        "This code implements FFJORD model based on the paper by Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever, David Duvenaud\n",
        "(paper link : [arXiv:1810.01367](https://arxiv.org/abs/1810.01367)).\n",
        "\n",
        "Using continuous normalizing flows, FFJORD is a generative model that effectively learns to map a complex data distribution onto a simple distribution. This is achieved through an invertible transformation modeled by a dynamic neural network."
      ],
      "metadata": {
        "id": "Sh1YLLCBJbiZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6LLC6x84sHv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Install the required library for ODEs (Ordinary Differential Equations)\n",
        "!pip install torchdiffeq\n",
        "\n",
        "# Standard imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "# The main tool for this project\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(42)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Parameters\n",
        "\n",
        "# MNIST has 28x28 images\n",
        "data_dim = 28 * 28\n",
        "SUBSET_PERCENTAGE = 0.4\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**1) Transformations and loader for the MNIST dataset**\n",
        "\n",
        "We are adding a slight random noise (dequantization) to shift the discrete pixel values into a continuous space. After normalizing the values and flattening the $28 \\times 28$ image into a long $784$-dimensional vector, a $40\\%$ subset of the MNIST data is selected and grouped into batches for efficient training.\n"
      ],
      "metadata": {
        "id": "OLvi45q4J_g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # Add uniform noise for dequantization (standard practice for continuous flows)\n",
        "    transforms.Lambda(lambda x: x + torch.rand_like(x) / 256.),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    # Flatten the 28x28 image into a 784-dimensional vector\n",
        "    transforms.Lambda(lambda x: x.view(-1)),])\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "# SUBSET SELECTION (40%)\n",
        "num_samples = len(train_dataset)\n",
        "subset_size = int(SUBSET_PERCENTAGE * num_samples)\n",
        "indices = torch.randperm(num_samples)[:subset_size]\n",
        "train_subset = torch.utils.data.Subset(train_dataset, indices)\n",
        "\n",
        "print(f\"Using {subset_size} samples ({SUBSET_PERCENTAGE*100}%) of the MNIST dataset.\")\n",
        "\n",
        "train_loader = DataLoader(dataset=train_subset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "SpUbb0dX5wua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2) FFJORD Model Definition**\n",
        "The neural network, defined as the dynamics function $\\mathbf{f}(\\mathbf{z}(t), t)$, is the core component of the flow. Parameterized by weights $\\mathbf{\\theta}$, this network learns the exact transformation dynamics. It takes the data's current position, $\\mathbf{z}(t)$, and the time step, $t$, as its input and returns the \"velocity\" $\\frac{d\\mathbf{z}}{dt}$, which determines the instantaneous direction and magnitude of the data flow.\n"
      ],
      "metadata": {
        "id": "kfBw7uBQXcWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Dynamics Network Code\n",
        "\n",
        "class DynamicsNet(nn.Module):\n",
        "    def __init__(self, hidden_dim=256):\n",
        "        super(DynamicsNet, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Input dimension is data_dim (784) + 1 (for time t)\n",
        "            nn.Linear(data_dim + 1, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            # Output dimension is data_dim (784)\n",
        "            nn.Linear(hidden_dim, data_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, t, z):\n",
        "        # We append time t as an extra dimension to each element of the batch\n",
        "        if t.dim() == 0: t = t.expand(z.size(0))\n",
        "        t = t.view(-1, 1)\n",
        "        # Concatenate the state z and the time t before passing them to the network\n",
        "        return self.net(torch.cat([z, t], dim=1))"
      ],
      "metadata": {
        "id": "iYT4UlUc52uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3) The Hutchinson's trace estimator**\n",
        "The primary computational bottleneck in continuous normalizing flows is the expensive calculation of the Jacobian determinant, which generally scales as $O(D^2)$, where $D$ is the dimensionality of the data. To address this complexity, Hutchinson's trace estimator is employed. This method estimates the trace of the Jacobian matrix, denoted as $\\mathbf{A}$, by calculating the mean of $\\mathbf{\\epsilon}^T \\mathbf{A} \\mathbf{\\epsilon}$. This quantity converges to the exact trace of $\\mathbf{A}$ by leveraging a random vector $\\mathbf{\\epsilon}$ (here, we are using Rademacher's distribution as mentionned in the paper)."
      ],
      "metadata": {
        "id": "tPJU1jE0Ygao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### The Hutchinson Estimator\n",
        "\n",
        "def hutchinson_trace_estimator(dynamics_fn, z, t, n_epsilons=1):\n",
        "    \"\"\"\n",
        "    Estimates the trace of the Jacobian of dynamics_fn with respect to z.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.enable_grad():\n",
        "      z.requires_grad_(True)\n",
        "\n",
        "      trace_estimates = []\n",
        "      for _ in range(n_epsilons):\n",
        "          # Sample a noise vector epsilon.\n",
        "          # The paper mentions a Rademacher or Gaussian distribution.\n",
        "          # We use Rademacher (values -1 or 1).\n",
        "          epsilon = torch.randint(low=0, high=2, size=z.shape, device=z.device) * 2 - 1\n",
        "          epsilon = epsilon.float()\n",
        "\n",
        "          # Calculate the product f(z, t) * epsilon.\n",
        "          # This is the first part of the \"vector-Jacobian product\" (VJP).\n",
        "          f_val = dynamics_fn(t, z)\n",
        "\n",
        "          # Calculate the vector-Jacobian product (VJP).\n",
        "          # This is the autodiff step : we compute (epsilon^T * J).\n",
        "          # torch.autograd.grad calculates the gradient of (f_val * epsilon).sum() with respect to z.\n",
        "          vjp_result, = torch.autograd.grad(f_val, z, grad_outputs=epsilon, create_graph=True, retain_graph=True)\n",
        "\n",
        "          # Calculate the final product (VJP * epsilon) to get the trace estimate.\n",
        "          trace_estimate = torch.sum(vjp_result * epsilon, dim=1)\n",
        "          trace_estimates.append(trace_estimate)\n",
        "\n",
        "      # Average the estimates if n_epsilons > 1.\n",
        "      final_trace = torch.mean(torch.stack(trace_estimates), dim=0)\n",
        "\n",
        "    return final_trace"
      ],
      "metadata": {
        "id": "G8mBgMeT591a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4) FFJORD Model Assembly**\n",
        "\n",
        "This model structure combines the flow dynamic ($\\frac{d\\mathbf{z}}{dt}$), the log-density change ($\\frac{d(\\log P)}{dt}$), and a kinetic regularization term into a single **Augmented Ordinary Differential Equation (ODE)**. The primary FFJORD class utilizes an ODE solver to integrate this system simultaneously, transforming the input data ($\\mathbf{x}$) into the simple base distribution ($\\mathbf{z}$), while automatically calculating the exact change in probability density necessary for training.\n"
      ],
      "metadata": {
        "id": "GvfTz4CzZZdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FFJORD MODEL\n",
        "\n",
        "class AugmentedDynamics(nn.Module):\n",
        "    \"\"\"\n",
        "    Defines the augmented derivative vector f_aug(t, z_aug) = [dz/dt, d(log P)/dt, d(Kinetic Reg)/dt].\n",
        "    This is the function that torchdiffeq will call repeatedly (at each step).\n",
        "    \"\"\"\n",
        "    def __init__(self, dynamics_net, n_epsilons):\n",
        "        super().__init__()\n",
        "        self.dynamics_net = dynamics_net\n",
        "        self.n_epsilons = n_epsilons\n",
        "        self.data_dim = 784\n",
        "\n",
        "    def forward(self, t, state):\n",
        "        # z is the first data_dim components. The state is  [z, log_p, kinetic_reg]\n",
        "        z = state[:, :self.data_dim]\n",
        "\n",
        "        # dz/dt = f(z, t)\n",
        "        dz_dt = self.dynamics_net(t, z)\n",
        "\n",
        "        # d(log p)/dt = -Tr(∂f/∂z)\n",
        "        dlogp_dt = -hutchinson_trace_estimator(self.dynamics_net, z, t, self.n_epsilons)\n",
        "\n",
        "        # d(Kinetic Reg)/dt = 0.5 * ||f(z, t)||^2\n",
        "        dkinetic_dt = 0.5 * torch.sum(dz_dt ** 2, dim=1)\n",
        "\n",
        "        # The augmented state derivatives are concatenated in the order: [dz/dt, d(log p)/dt, d(Kinetic Reg)/dt]\n",
        "        return torch.cat([dz_dt,\n",
        "                          dlogp_dt.view(-1, 1),\n",
        "                          dkinetic_dt.view(-1, 1)], dim=1)\n",
        "\n",
        "class FFJORD(nn.Module):\n",
        "    def __init__(self, dynamics_net, n_epsilons=1, lambda_reg=0.01):\n",
        "        super().__init__()\n",
        "        self.dynamics_net = dynamics_net\n",
        "        self.n_epsilons = n_epsilons\n",
        "        self.lambda_reg = lambda_reg\n",
        "        # We integrate from t=1 to t=0 for inference (used during training and evaluation/loss calculation)\n",
        "        self.integration_times_inference = torch.tensor([1.0, 0.0]).to(device)\n",
        "        # We integrate from t=0 to t=1 for generation (model creates new samples after training)\n",
        "        self.integration_times_generation = torch.tensor([0.0, 1.0]).to(device)\n",
        "\n",
        "        self.augmented_dynamics = AugmentedDynamics(dynamics_net, n_epsilons)\n",
        "\n",
        "        # SOLVER PARAMETERS\n",
        "        self.method = 'rk4'\n",
        "        self.rtol = 1e-7 # Relative tolerance\n",
        "        self.atol = 1e-8 # Absolute tolerance\n",
        "        self.solver_options = dict(step_size=0.03)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Base distribution, a Gaussian\n",
        "        base_dist = torch.distributions.MultivariateNormal(\n",
        "            loc=torch.zeros(data_dim).to(device),\n",
        "            covariance_matrix=torch.eye(data_dim).to(device)\n",
        "        )\n",
        "\n",
        "        # Initial log-probability (we start with a delta of 0).\n",
        "        log_px = torch.zeros(x.shape[0], 1).to(device)\n",
        "\n",
        "        # Initialize the kinetic regularization integral to 0\n",
        "        kinetic_reg = torch.zeros(x.shape[0], 1).to(device)\n",
        "\n",
        "        # We will solve the ODE for [z(t), log_p(z(t)), kinetic_reg] simultaneously.\n",
        "        # We concatenate x, the initial log_px, and kinetic_reg.\n",
        "        augmented_state = torch.cat([x, log_px, kinetic_reg], dim=1)\n",
        "\n",
        "        # ODE Solution\n",
        "        # We integrate from t=1 to t=0\n",
        "        solution = odeint(\n",
        "            self.augmented_dynamics,\n",
        "            augmented_state,\n",
        "            self.integration_times_inference,\n",
        "            method=self.method,\n",
        "            rtol=self.rtol,\n",
        "            atol=self.atol,\n",
        "            options=self.solver_options\n",
        "        )\n",
        "\n",
        "        # We retrieve z(t0), the total log-probability change, and the regularization term\n",
        "        z_t0 = solution[1][:, :data_dim]\n",
        "        # delta_log_p is the 2nd state (index data_dim)\n",
        "        delta_log_p = solution[1][:, data_dim:data_dim+1]\n",
        "        # delta_kinetic_reg is the 3rd state (index data_dim + 1)\n",
        "        delta_kinetic_reg = solution[1][:, data_dim+1:]\n",
        "\n",
        "        # Final log-probability: log p(z0) - ∫ Tr(df/dz) dt\n",
        "        log_pz0 = base_dist.log_prob(z_t0)\n",
        "        final_log_px = log_pz0.view(-1, 1) - delta_log_p\n",
        "\n",
        "        # Kinetic regularization loss: lambda_reg * ∫ 0.5 * ||f||^2 dt\n",
        "        reg_loss_term = self.lambda_reg * delta_kinetic_reg\n",
        "\n",
        "        return final_log_px, reg_loss_term\n",
        "\n",
        "    def generate(self, n_samples=64):\n",
        "        # We start from the base distribution\n",
        "        z0 = torch.rand(n_samples, data_dim) * 2 - 1\n",
        "        z0 = z0.to(device)\n",
        "\n",
        "        # Solve the ODE from t=0 to t=1 for generation\n",
        "        solution = odeint(\n",
        "            dynamics_net,\n",
        "            z0,\n",
        "            self.integration_times_generation,\n",
        "            method=self.method,\n",
        "            rtol=self.rtol,\n",
        "            atol=self.atol,\n",
        "            options=self.solver_options\n",
        "        )\n",
        "\n",
        "        # Get the final state z(t=1)\n",
        "        z_t1 = solution[-1]\n",
        "\n",
        "        # Force the generation to be between -1 and 1\n",
        "        z_t1 = torch.tanh(z_t1)\n",
        "        return z_t1"
      ],
      "metadata": {
        "id": "Usf-xGmv6AlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5) Image display for generation**"
      ],
      "metadata": {
        "id": "A0T-YuLVZ7JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_generations(images, title=\"Generated images\"):\n",
        "    fig, axes = plt.subplots(2, 8, figsize=(10,4))\n",
        "    axes = axes.flatten()\n",
        "    for i in range(min(16, len(images))):\n",
        "        img = images[i].view(28, 28).cpu().numpy()\n",
        "        # Normalize to [0, 1]\n",
        "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
        "        # If the background is too light, invert the image\n",
        "        if img_norm.mean() > 0.5:\n",
        "            img_norm = 1 - img_norm\n",
        "        axes[i].imshow(img_norm, cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "    fig.suptitle(title) # Set the title for the entire figure\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uTUHrmYf6DaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6) Training**\n"
      ],
      "metadata": {
        "id": "AOGqKpkqaEcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "\n",
        "# Parameters\n",
        "n_epochs = 100\n",
        "learning_rate = 1e-3\n",
        "n_epsilons_training = 1\n",
        "lambda_reg = 0.01\n",
        "\n",
        "# Initialization\n",
        "dynamics_net = DynamicsNet().to(device)\n",
        "ffjord_model = FFJORD(dynamics_net, n_epsilons=n_epsilons_training, lambda_reg=lambda_reg).to(device)\n",
        "optimizer = torch.optim.Adam(ffjord_model.parameters(), lr=learning_rate, weight_decay = 1e-5)\n",
        "\n",
        "# Initialize scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "print(\"Beginning of training...\")\n",
        "start_time = time.time()\n",
        "for epoch in tqdm.tqdm(range(n_epochs+1)):\n",
        "    total_loss = 0.0\n",
        "    ffjord_model.train()\n",
        "\n",
        "    for i, (x_batch, _) in enumerate(train_loader):\n",
        "\n",
        "        x_batch = x_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ffjord_model returns log-probability and regularization term\n",
        "        log_prob, reg_loss_term = ffjord_model(x_batch)\n",
        "\n",
        "        # Negative Log-Likelihood (NLL) Loss\n",
        "        nll_loss = -torch.mean(log_prob)\n",
        "\n",
        "        # Total Loss = NLL Loss + Kinetic Regularization Loss\n",
        "        loss = nll_loss + torch.mean(reg_loss_term)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(ffjord_model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    scheduler.step(avg_train_loss)\n",
        "    print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # Generation\n",
        "    ffjord_model.eval()\n",
        "    with torch.no_grad():\n",
        "        generated_images = ffjord_model.generate(n_samples=16)\n",
        "    # Display\n",
        "    if generated_images is not None:\n",
        "        # Example of generation after training\n",
        "        plot_generations(generated_images, title=f\"Generation (K={n_epsilons_training})\")\n",
        "\n",
        "\n",
        "    print(f'--- Epoch {epoch+1} finished, Average Loss: {total_loss / len(train_loader):.4f} ---')\n",
        "end_time = time.time()-start_time\n",
        "print(\"Training finished. process time: {}sec\".format(end_time))"
      ],
      "metadata": {
        "id": "k3Irg58e6J28"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}